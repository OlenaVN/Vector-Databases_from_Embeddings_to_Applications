{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlenaVN/Vector-Databases_from_Embeddings_to_Applications/blob/main/L1_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LisLhUSeZFJM"
      },
      "source": [
        "## Where do embeddings come from?\n",
        "### Embedding MNIST images and NLP sentences into vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHOrPYK2yxEP"
      },
      "source": [
        "\n",
        "\n",
        "[Source](https://en.wikipedia.org/wiki/Variational_autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 185,
        "id": "KgpR43oogbop"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import losses\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 66,
        "id": "RcoQ-OC6gboq",
        "outputId": "a19eb83e-0f97-4c6d-b945-2f3c03c054c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load data â€“ training and test\n",
        "(x_tr, y_tr), (x_te, y_te) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 83,
        "id": "9c7e-ZBHgbor"
      },
      "outputs": [],
      "source": [
        "#Normalize and Reshape images (flatten)\n",
        "x_tr, x_te = x_tr.astype('float32')/255., x_te.astype('float32')/255.\n",
        "x_tr_flat, x_te_flat = x_tr.reshape(x_tr.shape[0], -1), x_te.reshape(x_te.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "mUbxarukgbor",
        "outputId": "6c07d50b-a4a7-4634-c9f3-e1343c98eae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n",
            "(60000, 784) (10000, 784)\n"
          ]
        }
      ],
      "source": [
        "print(x_tr.shape, x_te.shape)\n",
        "print(x_tr_flat.shape, x_te_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "slgCp6EYgbos"
      },
      "outputs": [],
      "source": [
        "# Neural Network Parameters\n",
        "batch_size, n_epoch = 100, 50\n",
        "n_hidden, z_dim = 256, 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "yM_OfxIYgbos"
      },
      "outputs": [],
      "source": [
        "# Example of a training image\n",
        "plt.imshow(x_tr[1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 117,
        "id": "OBFEkY2kgbos"
      },
      "outputs": [],
      "source": [
        "# sampling function\n",
        "def sampling(args):\n",
        "    mu, log_var = args\n",
        "    eps = K.random_normal(shape=(batch_size, z_dim), mean=0., stddev=1.0)\n",
        "    return mu + K.exp(log_var) * eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 185,
        "id": "KHqv5jKQgbot"
      },
      "outputs": [],
      "source": [
        "# Encoder - from 784->256->128->2\n",
        "inputs_flat = Input(shape=(x_tr_flat.shape[1:]))\n",
        "x_flat = Dense(n_hidden, activation='relu')(inputs_flat) # first hidden layer\n",
        "x_flat = Dense(n_hidden//2, activation='relu')(x_flat)  # second hidden layer\n",
        "\n",
        "# hidden state, which we will pass into the Model to get the Encoder.\n",
        "mu_flat = Dense(z_dim)(x_flat)\n",
        "log_var_flat = Dense(z_dim)(x_flat)\n",
        "z_flat = Lambda(sampling, output_shape=(z_dim,))([mu_flat, log_var_flat])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 219,
        "id": "sv3qtu7Igbot"
      },
      "outputs": [],
      "source": [
        "#Decoder - from 2->128->256->784\n",
        "latent_inputs = Input(shape=(z_dim,))\n",
        "z_decoder1 = Dense(n_hidden//2, activation='relu')\n",
        "z_decoder2 = Dense(n_hidden, activation='relu')\n",
        "y_decoder = Dense(x_tr_flat.shape[1], activation='sigmoid')\n",
        "z_decoded = z_decoder1(latent_inputs)\n",
        "z_decoded = z_decoder2(z_decoded)\n",
        "y_decoded = y_decoder(z_decoded)\n",
        "decoder_flat = Model(latent_inputs, y_decoded, name=\"decoder_conv\")\n",
        "\n",
        "outputs_flat = decoder_flat(z_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 219,
        "id": "UDcS2Atygbot"
      },
      "outputs": [],
      "source": [
        "# variational autoencoder (VAE) - to reconstruction input\n",
        "reconstruction_loss = losses.binary_crossentropy(inputs_flat,\n",
        "                                                 outputs_flat) * x_tr_flat.shape[1]\n",
        "kl_loss = 0.5 * K.sum(K.square(mu_flat) + K.exp(log_var_flat) - log_var_flat - 1, axis = -1)\n",
        "vae_flat_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "# Build model\n",
        "#  Ensure that the reconstructed outputs are as close to the inputs\n",
        "vae_flat = Model(inputs_flat, outputs_flat)\n",
        "vae_flat.add_loss(vae_flat_loss)\n",
        "vae_flat.compile(optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 166,
        "id": "ks3lOcUTgbou",
        "outputId": "1a1afc74-4217-4b3e-f49d-2d69de3d39ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 134.2143 - val_loss: 136.2624\n",
            "Epoch 2/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 134.1017 - val_loss: 135.9934\n",
            "Epoch 3/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 134.0230 - val_loss: 135.9385\n",
            "Epoch 4/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 134.0521 - val_loss: 136.1526\n",
            "Epoch 5/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 134.1296 - val_loss: 135.7501\n",
            "Epoch 6/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 134.1687 - val_loss: 136.2865\n",
            "Epoch 7/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 134.0628 - val_loss: 136.4388\n",
            "Epoch 8/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.7536 - val_loss: 135.6931\n",
            "Epoch 9/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.5914 - val_loss: 135.6474\n",
            "Epoch 10/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.7623 - val_loss: 135.9394\n",
            "Epoch 11/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.4952 - val_loss: 135.8546\n",
            "Epoch 12/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.5187 - val_loss: 135.7839\n",
            "Epoch 13/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.4085 - val_loss: 136.1149\n",
            "Epoch 14/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.5068 - val_loss: 135.9511\n",
            "Epoch 15/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.4363 - val_loss: 135.3393\n",
            "Epoch 16/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.9811 - val_loss: 135.7150\n",
            "Epoch 17/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.2375 - val_loss: 135.2594\n",
            "Epoch 18/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.0360 - val_loss: 135.1716\n",
            "Epoch 19/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.1711 - val_loss: 135.7108\n",
            "Epoch 20/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.4203 - val_loss: 135.7464\n",
            "Epoch 21/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 133.2745 - val_loss: 135.2663\n",
            "Epoch 22/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.7327 - val_loss: 135.3540\n",
            "Epoch 23/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.7475 - val_loss: 135.4853\n",
            "Epoch 24/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.6775 - val_loss: 135.4402\n",
            "Epoch 25/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.7614 - val_loss: 135.8892\n",
            "Epoch 26/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.7210 - val_loss: 134.9373\n",
            "Epoch 27/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.5263 - val_loss: 135.0733\n",
            "Epoch 28/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.7206 - val_loss: 135.3414\n",
            "Epoch 29/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.4205 - val_loss: 135.2589\n",
            "Epoch 30/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.5484 - val_loss: 135.6900\n",
            "Epoch 31/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.3072 - val_loss: 135.1316\n",
            "Epoch 32/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.3755 - val_loss: 135.5874\n",
            "Epoch 33/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.5773 - val_loss: 135.4695\n",
            "Epoch 34/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.3858 - val_loss: 134.8566\n",
            "Epoch 35/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.4511 - val_loss: 135.0404\n",
            "Epoch 36/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.2451 - val_loss: 135.3833\n",
            "Epoch 37/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.4745 - val_loss: 134.8219\n",
            "Epoch 38/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.2476 - val_loss: 134.9680\n",
            "Epoch 39/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.0910 - val_loss: 134.9110\n",
            "Epoch 40/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.2871 - val_loss: 134.5206\n",
            "Epoch 41/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 131.9180 - val_loss: 135.1285\n",
            "Epoch 42/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.2838 - val_loss: 135.2444\n",
            "Epoch 43/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.0039 - val_loss: 134.9584\n",
            "Epoch 44/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 132.0977 - val_loss: 134.3495\n",
            "Epoch 45/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 131.7391 - val_loss: 134.8372\n",
            "Epoch 46/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 131.8696 - val_loss: 135.0118\n",
            "Epoch 47/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 131.7996 - val_loss: 134.9527\n",
            "Epoch 48/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 131.5132 - val_loss: 134.4846\n",
            "Epoch 49/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 131.6872 - val_loss: 134.7806\n",
            "Epoch 50/50\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 131.6114 - val_loss: 134.3961\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fda63895220>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train\n",
        "vae_flat.fit(\n",
        "    x_tr_flat,\n",
        "    shuffle=True,\n",
        "    epochs=n_epoch,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(x_te_flat, None),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OeUdzjmgbou"
      },
      "source": [
        "### Visualize Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 66,
        "id": "N5La6OA9gbou"
      },
      "outputs": [],
      "source": [
        "# Build encoders\n",
        "encoder_f = Model(inputs_flat, z_flat)  # flat encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 151,
        "id": "YCT-J5Xmgbov"
      },
      "outputs": [],
      "source": [
        "# Plot of the digit classes in the latent space\n",
        "x_te_latent = encoder_f.predict(x_te_flat, batch_size=batch_size,verbose=0)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x_te_latent[:, 0], x_te_latent[:, 1], c=y_te, alpha=0.75)\n",
        "plt.title('MNIST 2D Embeddings')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeYkzFzTgbov"
      },
      "source": [
        "## Example: compare three embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "8r_dQr4Jgbov"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_te_flat[10].reshape(28,28));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "oDcSZAJrgbov"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_te_flat[13].reshape(28,28));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "JT6MIvKBgbow"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_te_flat[2].reshape(28,28));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 168,
        "id": "l_1RijDRgbow",
        "outputId": "03b8b024-d8f6-4dab-c975-c661ab2e8ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding for the first ZERO is  [ 0.42951003 -1.4916214 ]\n",
            "Embedding for the second ZERO is [ 0.40792125 -1.2463808 ]\n",
            "Embedding for the ONE is         [-0.96056986  1.5310994 ]\n"
          ]
        }
      ],
      "source": [
        "# calculate vectors for each digit\n",
        "zero_A = x_te_latent[10]\n",
        "zero_B = x_te_latent[13]\n",
        "one = x_te_latent[2]\n",
        "\n",
        "print(f\"Embedding for the first ZERO is  {zero_A}\")\n",
        "print(f\"Embedding for the second ZERO is {zero_B}\")\n",
        "print(f\"Embedding for the ONE is         {one}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G6SfrV8gbow"
      },
      "source": [
        "## Using more advanced models based on the Transformer architechture you can embed sentences aswell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 83,
        "id": "T3q2pr4ugbox"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "5WUFTzZrgbox"
      },
      "outputs": [],
      "source": [
        "#Sentences we want to encode. Example:\n",
        "sentence = ['The team enjoyed the hike through the meadow',\n",
        "            'The national park had great views',\n",
        "            'Olive oil drizzled over pizza tastes delicious']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 117,
        "id": "ICb15cecgbox",
        "outputId": "f1efe139-a350-4133-d7e9-a1a07771efaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.3706196   0.26414266  0.21265697 ...  0.14994529 -0.25794923\n",
            "  -0.23970787]\n",
            " [ 0.6693329   0.40094936 -0.48208413 ...  0.10645889 -1.5067163\n",
            "  -0.01547364]\n",
            " [-0.26555923  0.11172373 -0.14733098 ...  0.42197487  0.88394576\n",
            "   0.10763898]]\n"
          ]
        }
      ],
      "source": [
        "#Sentences are encoded by calling model.encode()\n",
        "embedding = model.encode(sentence)\n",
        "\n",
        "#Preview the embeddings\n",
        "print(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "Pf3ZsPO8gbox",
        "outputId": "2fa893b4-1780-45ab-d0e6-057ce6b149f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 384)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 321,
        "id": "oemdndODgbox"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(embedding[0].reshape(-1,384),cmap=\"Greys\",center=0,square=False)\n",
        "plt.gcf().set_size_inches(10,1)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "sns.heatmap(embedding[1].reshape(-1,384),cmap=\"Greys\",center=0,square=False)\n",
        "plt.gcf().set_size_inches(10,1)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "sns.heatmap(embedding[2].reshape(-1,384),cmap=\"Greys\",center=0,square=False)\n",
        "plt.gcf().set_size_inches(10,1)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn5NFuCggbox"
      },
      "source": [
        "## How can we measure the distance between these Image and Sentence Embeddings?\n",
        "\n",
        "There are many ways to calculate the distances between two vectors.\n",
        "\n",
        "Here we will cover 4 distance metrics that you might find being used in the context of vector databases:\n",
        "- Euclidean Distance(L2)\n",
        "- Manhattan Distance(L1)\n",
        "- Dot Product\n",
        "- Cosine Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgPTZATEgbox"
      },
      "source": [
        "### Euclidean Distance(L2)\n",
        "The length of the shortest path between two points or vectors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "4rn2ZczBgboz",
        "outputId": "c72d0db8-21b8-4288-da84-354f72d70433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.24618897586869437\n"
          ]
        }
      ],
      "source": [
        "# Euclidean Distance\n",
        "L2 = [(zero_A[i] - zero_B[i])**2 for i in range(len(zero_A))]\n",
        "L2 = np.sqrt(np.array(L2).sum())\n",
        "print(L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "2g6TCYgPgboz",
        "outputId": "aff197e2-1819-4de8-f434-bc8eb2ffc21f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.24618898"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#An alternative way of doing this\n",
        "np.linalg.norm((zero_A - zero_B), ord=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "wuvokZtcgboz",
        "outputId": "9a8759a1-efcb-4152-b912-c5a381a342fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance zeroA-zeroB: 0.24618898\n",
            "Distance zeroA-one:   3.3270352\n",
            "Distance zeroB-one:   3.0963147\n"
          ]
        }
      ],
      "source": [
        "#Calculate L2 distances\n",
        "print(\"Distance zeroA-zeroB:\", np.linalg.norm((zero_A - zero_B), ord=2))\n",
        "print(\"Distance zeroA-one:  \", np.linalg.norm((zero_A - one), ord=2))\n",
        "print(\"Distance zeroB-one:  \", np.linalg.norm((zero_B - one), ord=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l510muUgbo0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 117,
        "id": "ohAcMzNGgbo1",
        "outputId": "76041f1c-bac3-4f6c-e1e0-24963ebef629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.26682934\n"
          ]
        }
      ],
      "source": [
        "# Manhattan Distance\n",
        "L1 = [zero_A[i] - zero_B[i] for i in range(len(zero_A))]\n",
        "L1 = np.abs(L1).sum()\n",
        "\n",
        "print(L1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "sM1OmpbEgbo1",
        "outputId": "88af1091-aac2-4952-a5b8-c110ed888dc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.26682934"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#an alternative way of doing this is\n",
        "np.linalg.norm((zero_A - zero_B), ord=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "bi0P4iP5gbo1",
        "outputId": "07e2e9c6-5917-4ea7-9ab7-4ef83c664cd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance zeroA-zeroB: 0.26682934\n",
            "Distance zeroA-one:   4.412801\n",
            "Distance zeroB-one:   4.1459713\n"
          ]
        }
      ],
      "source": [
        "#Calculate L1 distances\n",
        "print(\"Distance zeroA-zeroB:\", np.linalg.norm((zero_A - zero_B), ord=1))\n",
        "print(\"Distance zeroA-one:  \", np.linalg.norm((zero_A - one), ord=1))\n",
        "print(\"Distance zeroB-one:  \", np.linalg.norm((zero_B - one), ord=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "LUKbzHzDgbo2",
        "outputId": "dd981267-2682-4e18-e736-827b0e10bd4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.0343344"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dot Product\n",
        "np.dot(zero_A,zero_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "m8n_cjlQgbo2",
        "outputId": "4a3ca50d-29a8-45e5-a379-676c3b95aa33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance zeroA-zeroB: 2.0343344\n",
            "Distance zeroA-one:   -2.696395\n",
            "Distance zeroB-one:   -2.3001697\n"
          ]
        }
      ],
      "source": [
        "#Calculate Dot products\n",
        "print(\"Distance zeroA-zeroB:\", np.dot(zero_A, zero_B))\n",
        "print(\"Distance zeroA-one:  \", np.dot(zero_A, one))\n",
        "print(\"Distance zeroB-one:  \", np.dot(zero_B, one))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 83,
        "id": "fpz_qQrlgbo8",
        "outputId": "813acd1a-035f-4062-d587-2248e114cc0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.000646\n"
          ]
        }
      ],
      "source": [
        "# Cosine Distance\n",
        "cosine = 1 - np.dot(zero_A,zero_B)/(np.linalg.norm(zero_A)*np.linalg.norm(zero_B))\n",
        "print(f\"{cosine:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "pr-rMOGygbo8",
        "outputId": "69cab26c-543e-4a16-82e8-2a4724564e10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.0529239, 1.1967622], dtype=float32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zero_A/zero_B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "eL_pVdOVgbo9"
      },
      "outputs": [],
      "source": [
        "# Cosine Distance function\n",
        "def cosine_distance(vec1,vec2):\n",
        "  cosine = 1 - (np.dot(vec1, vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2)))\n",
        "  return cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "XdAxvL55gbo9",
        "outputId": "c819d722-57e4-4db6-c93f-82e5338b37b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance zeroA-zeroB:  0.000646\n",
            "Distance zeroA-one:    1.961072\n",
            "Distance zeroB-one:    1.970378\n"
          ]
        }
      ],
      "source": [
        "#Cosine Distance\n",
        "print(f\"Distance zeroA-zeroB: {cosine_distance(zero_A, zero_B): .6f}\")\n",
        "print(f\"Distance zeroA-one:   {cosine_distance(zero_A, one): .6f}\")\n",
        "print(f\"Distance zeroB-one:   {cosine_distance(zero_B, one): .6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vQGj7pNgbo9"
      },
      "source": [
        "## Now with the sentence embeddings!\n",
        "\n",
        "Dot Product and Cosine Distance are commonly used in the field of NLP, to evaluate how similar two sentence embeddings are.\n",
        "So here we will only use those two.\n",
        "\n",
        "- embedding0 - 'The team enjoyed the hike through the meadow'\n",
        "\n",
        "- embedding1 - The national park had great views'\n",
        "\n",
        "- embedding2 - 'Olive oil drizzled over pizza tastes delicious'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "lcWs_mahgbo9",
        "outputId": "a20ed234-fa5e-485d-f129-661bfd49a885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance 0-1: 26.497883\n",
            "Distance 0-2: 2.0785882\n",
            "Distance 1-2: 4.0192223\n"
          ]
        }
      ],
      "source": [
        "#Dot Product\n",
        "print(\"Distance 0-1:\", np.dot(embedding[0], embedding[1]))\n",
        "print(\"Distance 0-2:\", np.dot(embedding[0], embedding[2]))\n",
        "print(\"Distance 1-2:\", np.dot(embedding[1], embedding[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 100,
        "id": "uT_owD7kgbo9",
        "outputId": "30d16980-dd10-454f-adb6-6af466abdec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance 0-1:  0.5350336730480194\n",
            "Distance 0-2:  0.9639391340315342\n",
            "Distance 1-2:  0.9288789108395576\n"
          ]
        }
      ],
      "source": [
        "#Cosine Distance\n",
        "print(\"Distance 0-1: \", cosine_distance(embedding[0], embedding[1]))\n",
        "print(\"Distance 0-2: \", cosine_distance(embedding[0], embedding[2]))\n",
        "print(\"Distance 1-2: \", cosine_distance(embedding[1], embedding[2]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}